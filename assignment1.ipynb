{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQArQEABq5IdY47sWXtoOE"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas polars duckdb pyarrow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRrkSgpOF4rn",
        "outputId": "d35f33ce-3ca7-4535-960a-8ec908568ccf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (1.31.0)\n",
            "Requirement already satisfied: duckdb in /usr/local/lib/python3.12/dist-packages (1.3.2)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (18.1.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part 1: Data Ingestion"
      ],
      "metadata": {
        "id": "GC1Cbqr8xOp1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.** Programmatic Download"
      ],
      "metadata": {
        "id": "9NWVl74Wz895"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jDomYP_Rw-Yj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cd1031a-bb42-465b-e451-e3904d4389eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet...\n",
            "Downloaded to data/raw/yellow_tripdata_2024_01.parquet\n",
            "Downloading https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv...\n",
            "Downloaded to data/raw/taxi_zone_lookup.csv\n",
            "All downloads completed.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "down_dir = Path(\"data/raw\")\n",
        "down_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "download = [\n",
        "    {\n",
        "        'url': 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet',\n",
        "        'filename': down_dir / 'yellow_tripdata_2024_01.parquet'\n",
        "    },\n",
        "    {\n",
        "        'url': 'https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv',\n",
        "        'filename': down_dir / 'taxi_zone_lookup.csv'\n",
        "    }\n",
        "]\n",
        "\n",
        "for file in download:\n",
        "  print(f'Downloading {file['url']}...')\n",
        "\n",
        "  response = requests.get(file['url'], stream=True)\n",
        "\n",
        "  response.raise_for_status()\n",
        "\n",
        "  with open(file['filename'], 'wb') as f:\n",
        "    for chunk in response.iter_content(chunk_size=8192):\n",
        "      f.write(chunk)\n",
        "\n",
        "  print(f'Downloaded to {file['filename']}')\n",
        "\n",
        "print('All downloads completed.')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above uses a \"requests\" implementation to download and store necessary files."
      ],
      "metadata": {
        "id": "wPbxbBFj9-AD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.** Data validation"
      ],
      "metadata": {
        "id": "aP1QFVC29M9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "import time\n",
        "\n",
        "#a) verifing expected columns exist\n",
        "ex_cols = ['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'PULocationID', 'DOLocationID', 'passenger_count', 'trip_distance', 'fare_amount', 'tip_amount', 'total_amount', 'payment_type']\n",
        "\n",
        "taxi_schema = pl.read_parquet_schema(down_dir / 'yellow_tripdata_2024_01.parquet')\n",
        "\n",
        "actual_cols = list(taxi_schema.keys())\n",
        "\n",
        "missing_cols = [col for col in ex_cols if col not in actual_cols]\n",
        "\n",
        "if not missing_cols:\n",
        "  print(f'\\nAll expected columns exist: {ex_cols}')\n",
        "else:\n",
        "  # d.a)\n",
        "  print(f'\\nDataset is missing the following expected coloumns: {missing_cols}')\n",
        "  raise Exception('Missing expected columns.')\n",
        "\n",
        "#b) checking for valid datatime type in datetime columns\n",
        "date_cols = ['tpep_pickup_datetime', 'tpep_dropoff_datetime']\n",
        "\n",
        "for col in date_cols:\n",
        "  if col in taxi_schema:\n",
        "    datet = taxi_schema[col]\n",
        "    if datet == pl.Datetime:\n",
        "      print(f'\\ncolumn {col} is of {datet} type')\n",
        "    else:\n",
        "      print(f'\\ncolumn {col} is not of datetime type')\n",
        "      raise Exception(f'column {col} is not of datetime type')\n",
        "\n",
        "#c) Report total row count and print a summary to the console\n",
        "df_taxi = pl.read_parquet(down_dir / 'yellow_tripdata_2024_01.parquet')\n",
        "print(f'\\nNumber of rows in the dataset: {len(df_taxi):,}')\n",
        "print(f'Number of columns in the dataset: {len(df_taxi.columns):,}')\n",
        "print('\\nColumn names and types:')\n",
        "print(taxi_schema)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wl7NTTQG9kzJ",
        "outputId": "d446f4da-a519-4f25-9a4c-ef363c5da6da"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "All expected columns exist: ['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'PULocationID', 'DOLocationID', 'passenger_count', 'trip_distance', 'fare_amount', 'tip_amount', 'total_amount', 'payment_type']\n",
            "\n",
            "column tpep_pickup_datetime is of Datetime(time_unit='ns', time_zone=None) type\n",
            "\n",
            "column tpep_dropoff_datetime is of Datetime(time_unit='ns', time_zone=None) type\n",
            "\n",
            "Number of rows in the dataset: 2,964,624\n",
            "Number of columns in the dataset: 19\n",
            "\n",
            "Column names and types:\n",
            "{'VendorID': Int32, 'tpep_pickup_datetime': Datetime(time_unit='ns', time_zone=None), 'tpep_dropoff_datetime': Datetime(time_unit='ns', time_zone=None), 'passenger_count': Int64, 'trip_distance': Float64, 'RatecodeID': Int64, 'store_and_fwd_flag': String, 'PULocationID': Int32, 'DOLocationID': Int32, 'payment_type': Int64, 'fare_amount': Float64, 'extra': Float64, 'mta_tax': Float64, 'tip_amount': Float64, 'tolls_amount': Float64, 'improvement_surcharge': Float64, 'total_amount': Float64, 'congestion_surcharge': Float64, 'Airport_fee': Float64}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.** File organisation (.gitignore)"
      ],
      "metadata": {
        "id": "7Uz4FedI1fsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DQ6lS8Oz2Rmr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}